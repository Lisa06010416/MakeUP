{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lisa.utils.logger import get_logger\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data._utils.collate import default_collate\n",
    "import numpy\n",
    "from PIL import Image\n",
    "from typing import Optional\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"data/makeup color test/Train/face color test/3.jpg\"\n",
    "img = Image.open(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### image process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = transforms.Compose([transforms.Resize(image_size), transforms.CenterCrop(image_size), \n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\n",
    "img = tfms(img).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 準備訓練資料\n",
    "# ImageFolder假設指定路徑下有多個資料夾，每個資料夾內為同一類的圖片，資料加名稱類別名\n",
    "data_path = \"data/makeup color test/Train/\"\n",
    "train_dataset = datasets.ImageFolder(data_path,\n",
    "                                     transforms.Compose([\n",
    "                                        transforms.Resize(image_size),\n",
    "                                        transforms.CenterCrop(image_size),\n",
    "                                        transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "                                        transforms.RandomHorizontalFlip(),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                                     ]))\n",
    "train_dataloader =  torch.utils.data.DataLoader(train_dataset, \n",
    "                                                batch_size=2, \n",
    "                                                shuffle=True, \n",
    "                                                num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.4166,  0.3138,  0.3823,  ...,  2.2489, -2.1179, -2.1179],\n",
      "          [ 0.5364, -0.6965, -1.7240,  ...,  2.2489, -2.1179, -2.1179],\n",
      "          [ 2.1804,  1.6324, -0.8507,  ...,  2.2489, -2.1179, -2.1179],\n",
      "          ...,\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[ 0.5378,  0.4503,  0.6954,  ...,  2.4286, -2.0357, -2.0357],\n",
      "          [ 0.5203, -0.8627, -1.3179,  ...,  2.4286, -2.0357, -2.0357],\n",
      "          [ 2.3235,  1.4657, -0.7927,  ...,  2.4286, -2.0357, -2.0357],\n",
      "          ...,\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[ 0.7228,  0.6705,  1.1062,  ...,  2.6400, -1.8044, -1.8044],\n",
      "          [ 0.5485, -0.9156, -0.6890,  ...,  2.6400, -1.8044, -1.8044],\n",
      "          [ 2.4831,  1.2282, -0.4450,  ...,  2.6400, -1.8044, -1.8044],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [ 1.9578,  1.9578,  1.9578,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          ...,\n",
      "          [ 1.9578,  1.9578,  1.9578,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [ 1.9578,  1.9578,  1.9578,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [ 1.9578,  1.9578,  1.9578,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [ 2.1310,  2.1310,  2.1310,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          ...,\n",
      "          [ 2.1310,  2.1310,  2.1310,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [ 2.1310,  2.1310,  2.1310,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [ 2.1310,  2.1310,  2.1310,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [ 2.3437,  2.3437,  2.3437,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          ...,\n",
      "          [ 2.3437,  2.3437,  2.3437,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [ 2.3437,  2.3437,  2.3437,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [ 2.3437,  2.3437,  2.3437,  ..., -1.8044, -1.8044, -1.8044]]]])\n",
      "tensor([2, 5])\n",
      "tensor([[[[-2.1179, -2.1179, -2.1179,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.1179, -2.1179, -2.1179,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.1179, -2.1179, -2.1179,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [-2.1179, -2.1179, -2.1179,  ...,  2.0605,  2.1462,  2.2489],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[-2.0357, -2.0357, -2.0357,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  2.2185,  2.3761,  2.4286],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[-1.8044, -1.8044, -1.8044,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.8044, -1.8044, -1.8044,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.8044, -1.8044, -1.8044,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -1.8044,  ...,  2.4134,  2.6226,  2.6400],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "        [[[-2.1179, -2.1179,  1.9578,  ...,  1.9578,  1.9578,  1.9578],\n",
      "          [-2.1179, -2.1179,  1.9578,  ...,  1.9578,  1.9578,  1.9578],\n",
      "          [-2.1179, -2.1179,  1.9578,  ...,  1.9578,  1.9578,  1.9578],\n",
      "          ...,\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[-2.0357, -2.0357,  2.1310,  ...,  2.1310,  2.1310,  2.1310],\n",
      "          [-2.0357, -2.0357,  2.1310,  ...,  2.1310,  2.1310,  2.1310],\n",
      "          [-2.0357, -2.0357,  2.1310,  ...,  2.1310,  2.1310,  2.1310],\n",
      "          ...,\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[-1.8044, -1.8044,  2.3437,  ...,  2.3437,  2.3437,  2.3437],\n",
      "          [-1.8044, -1.8044,  2.3437,  ...,  2.3437,  2.3437,  2.3437],\n",
      "          [-1.8044, -1.8044,  2.3437,  ...,  2.3437,  2.3437,  2.3437],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]])\n",
      "tensor([4, 2])\n",
      "tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          ...,\n",
      "          [ 1.9578,  1.9578,  1.9578,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [ 1.9578,  1.9578,  1.9578,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [ 1.9578,  1.9578,  1.9578,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          ...,\n",
      "          [ 2.1310,  2.1310,  2.1310,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [ 2.1310,  2.1310,  2.1310,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [ 2.1310,  2.1310,  2.1310,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          ...,\n",
      "          [ 2.3437,  2.3437,  2.3437,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [ 2.3437,  2.3437,  2.3437,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [ 2.3437,  2.3437,  2.3437,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          ...,\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          ...,\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]])\n",
      "tensor([4, 5])\n",
      "tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          ...,\n",
      "          [-2.1179, -2.1179, -2.1179,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.1179, -2.1179, -2.1179,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [-2.1179, -2.1179, -2.1179,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          ...,\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -1.8044,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.8044, -1.8044, -1.8044,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [-1.8044, -1.8044, -1.8044,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          ...,\n",
      "          [-2.1179, -2.1179,  0.3823,  ...,  0.4508, -1.0390,  1.7352],\n",
      "          [-2.1179, -2.1179,  1.7865,  ..., -0.1999, -1.1589,  1.2043],\n",
      "          [-2.1179, -2.1179,  2.2489,  ...,  1.6495,  1.5639,  1.9064]],\n",
      "\n",
      "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          ...,\n",
      "          [-2.0357, -2.0357, -0.1275,  ..., -0.1275, -0.3725,  1.9559],\n",
      "          [-2.0357, -2.0357,  1.6583,  ..., -0.5651, -0.7052,  1.6583],\n",
      "          [-2.0357, -2.0357,  2.4111,  ...,  1.7633,  1.7458,  2.1660]],\n",
      "\n",
      "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -0.4624,  ..., -0.5495,  0.4614,  2.0823],\n",
      "          [-1.8044, -1.8044,  1.4548,  ..., -0.7413, -0.0441,  2.0823],\n",
      "          [-1.8044, -1.8044,  2.5877,  ...,  1.9428,  2.0125,  2.4657]]]])\n",
      "tensor([1, 3])\n",
      "tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          ...,\n",
      "          [-2.1179, -2.1179, -2.1179,  ...,  1.9578,  1.9578,  1.9578],\n",
      "          [-2.1179, -2.1179, -2.1179,  ...,  1.9578,  1.9578,  1.9578],\n",
      "          [-2.1179, -2.1179, -2.1179,  ...,  1.9578,  1.9578,  1.9578]],\n",
      "\n",
      "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          ...,\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  2.1310,  2.1310,  2.1310],\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  2.1310,  2.1310,  2.1310],\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  2.1310,  2.1310,  2.1310]],\n",
      "\n",
      "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -1.8044,  ...,  2.3437,  2.3437,  2.3437],\n",
      "          [-1.8044, -1.8044, -1.8044,  ...,  2.3437,  2.3437,  2.3437],\n",
      "          [-1.8044, -1.8044, -1.8044,  ...,  2.3437,  2.3437,  2.3437]]],\n",
      "\n",
      "\n",
      "        [[[-2.1179, -2.1179, -2.1179,  ...,  1.6667,  1.6667,  1.6667],\n",
      "          [-2.1179, -2.1179, -2.1179,  ...,  1.6667,  1.6667,  1.6667],\n",
      "          [-2.1179, -2.1179, -2.1179,  ...,  1.6667,  1.6667,  1.6667],\n",
      "          ...,\n",
      "          [-2.1179, -2.1179, -2.1179,  ...,  1.1872,  1.2728,  1.3755],\n",
      "          [-2.1179, -2.1179, -2.1179,  ...,  1.2385,  1.2899,  1.3584],\n",
      "          [-2.1179, -2.1179, -2.1179,  ...,  1.2728,  1.3070,  1.3584]],\n",
      "\n",
      "         [[-2.0357, -2.0357, -2.0357,  ...,  1.9734,  1.9734,  1.9734],\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  1.9734,  1.9734,  1.9734],\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  1.9734,  1.9734,  1.9734],\n",
      "          ...,\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  0.4503,  0.5378,  0.6429],\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  0.5028,  0.5553,  0.6254],\n",
      "          [-2.0357, -2.0357, -2.0357,  ...,  0.5378,  0.5728,  0.6254]],\n",
      "\n",
      "         [[-1.8044, -1.8044, -1.8044,  ...,  2.2391,  2.2391,  2.2391],\n",
      "          [-1.8044, -1.8044, -1.8044,  ...,  2.2391,  2.2391,  2.2391],\n",
      "          [-1.8044, -1.8044, -1.8044,  ...,  2.2391,  2.2391,  2.2391],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -0.1487, -0.0615,  0.0431],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -0.0964, -0.0441,  0.0256],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -0.0615, -0.0267,  0.0256]]]])\n",
      "tensor([3, 1])\n"
     ]
    }
   ],
   "source": [
    "for i,j in train_dataloader:\n",
    "    print(i)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.3452e-01, -2.4137e-01, -2.5781e-01,  ..., -1.5725e-01,\n",
       "           -1.5298e-01, -1.8575e-01],\n",
       "          [-1.2318e-01, -2.1992e-01, -7.1795e-02,  ..., -2.2001e-01,\n",
       "           -1.3432e-01, -6.8094e-02],\n",
       "          [-1.1476e-01, -4.0598e-02, -5.9860e-04,  ..., -8.5880e-02,\n",
       "           -5.6209e-02, -1.2070e-02],\n",
       "          ...,\n",
       "          [ 9.4377e-01, -2.7345e-01, -1.3477e-01,  ..., -2.2265e-01,\n",
       "           -2.3221e-01, -1.8630e-01],\n",
       "          [ 6.4874e-02, -2.7123e-01, -2.7594e-01,  ..., -4.1425e-02,\n",
       "            2.6047e+00,  2.6346e+00],\n",
       "          [-2.7560e-01, -5.7917e-02, -1.5357e-02,  ..., -4.1297e-03,\n",
       "            9.3423e-01,  2.4052e+00]],\n",
       "\n",
       "         [[ 2.7389e+00,  5.4472e-01, -1.5927e-01,  ..., -1.3962e-01,\n",
       "           -1.9566e-01, -1.6196e-01],\n",
       "          [ 4.6547e-01, -2.7000e-01, -2.3767e-01,  ..., -1.1946e-01,\n",
       "           -9.5869e-02, -1.3298e-01],\n",
       "          [-1.3458e-01,  2.9402e+00,  6.5549e+00,  ..., -1.7072e-01,\n",
       "           -8.7656e-02, -2.1018e-02],\n",
       "          ...,\n",
       "          [-3.8878e-02, -1.2570e-01, -1.3255e-01,  ..., -6.3348e-02,\n",
       "           -8.7236e-02, -4.5172e-02],\n",
       "          [-3.6661e-02, -1.3563e-01, -2.0460e-01,  ..., -1.5433e-01,\n",
       "           -1.1018e-01, -3.2686e-02],\n",
       "          [-6.5898e-02, -1.4945e-01, -2.2132e-01,  ..., -8.3504e-02,\n",
       "           -2.9836e-02, -5.2534e-03]],\n",
       "\n",
       "         [[ 3.1066e+00,  1.8527e+00, -2.7833e-01,  ..., -4.9963e-02,\n",
       "           -8.8652e-02,  6.5850e-02],\n",
       "          [ 7.3108e-01,  4.0445e-01,  8.7141e-01,  ...,  7.2461e-01,\n",
       "           -2.3810e-01, -2.7816e-01],\n",
       "          [-2.5662e-01, -1.4587e-01, -6.4111e-02,  ...,  9.3523e-01,\n",
       "           -2.5627e-01, -1.6503e-01],\n",
       "          ...,\n",
       "          [-2.7801e-01, -1.7495e-01, -2.6036e-02,  ..., -6.5514e-02,\n",
       "           -4.1851e-02, -1.6881e-01],\n",
       "          [ 1.3536e-01, -2.4603e-01, -1.1712e-02,  ..., -1.5842e-02,\n",
       "           -5.9840e-02, -2.0441e-01],\n",
       "          [-2.1442e-01, -2.7644e-01, -6.1044e-02,  ..., -2.0216e-01,\n",
       "           -1.6737e-01,  6.0390e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.8526e-02, -2.7461e-01, -2.9149e-02,  ..., -2.5793e-01,\n",
       "           -1.8310e-01, -2.3476e-01],\n",
       "          [-9.1171e-03, -1.8040e-01, -2.1662e-03,  ...,  1.5228e-01,\n",
       "           -9.1508e-02, -4.8982e-02],\n",
       "          [-3.1623e-02, -7.2412e-02, -6.1235e-03,  ...,  3.7160e+00,\n",
       "           -1.9440e-02, -8.1549e-03],\n",
       "          ...,\n",
       "          [-3.7165e-02,  2.8804e+00, -2.7054e-01,  ..., -8.1596e-02,\n",
       "           -1.8152e-01, -1.6235e-01],\n",
       "          [-1.8541e-01,  1.2476e+00, -2.7654e-01,  ..., -2.7451e-01,\n",
       "            1.3107e+00,  2.2416e+00],\n",
       "          [-8.6709e-02,  6.0773e-01, -2.4883e-01,  ..., -1.2458e-01,\n",
       "            3.8217e-01, -1.6972e-01]],\n",
       "\n",
       "         [[ 2.2551e+00,  6.0052e-01, -2.4977e-01,  ..., -1.4161e-01,\n",
       "           -1.3163e-01, -7.9653e-02],\n",
       "          [-2.4188e-01, -1.0390e-01, -4.3777e-03,  ..., -2.2704e-01,\n",
       "           -2.5686e-01, -7.4469e-02],\n",
       "          [-2.3338e-01, -6.0560e-02, -1.7029e-01,  ..., -2.3719e-01,\n",
       "           -1.2363e-01, -3.4538e-02],\n",
       "          ...,\n",
       "          [-2.7706e-01, -1.9158e-01, -2.2642e-01,  ..., -2.3535e-02,\n",
       "           -1.0416e-01, -6.2329e-02],\n",
       "          [-2.5464e-01, -1.2644e-01, -2.2762e-01,  ..., -2.7299e-02,\n",
       "            2.7510e+00,  1.1560e+00],\n",
       "          [-1.3804e-01, -4.2860e-02, -2.9964e-02,  ..., -2.6862e-01,\n",
       "            1.8777e+00,  4.3902e-01]],\n",
       "\n",
       "         [[-9.0136e-02, -2.6476e-01, -4.5581e-02,  ..., -2.2244e-01,\n",
       "           -2.6966e-01, -1.9778e-01],\n",
       "          [-1.8305e-01, -2.6823e-01, -1.5727e-02,  ..., -4.3137e-02,\n",
       "           -1.7873e-01, -2.0417e-01],\n",
       "          [-2.7578e-01, -3.1716e-02, -1.5204e-02,  ..., -2.7837e-01,\n",
       "           -1.2219e-01, -2.6803e-01],\n",
       "          ...,\n",
       "          [-2.7816e-01, -1.9544e-01, -1.8609e-01,  ...,  9.9877e-01,\n",
       "            1.6950e+00,  1.0449e+00],\n",
       "          [-2.4733e-01, -2.7062e-01, -2.5310e-02,  ...,  4.1362e-01,\n",
       "            3.1088e+00,  3.0251e+00],\n",
       "          [-2.2934e-01, -2.6225e-01, -2.5565e-01,  ..., -4.5447e-02,\n",
       "           -2.7733e-01, -1.6998e-02]]]], grad_fn=<SwishImplementationBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EfficientNet.from_pretrained('efficientnet-b0', num_classes = 5)\n",
    "image_size = EfficientNet.get_image_size('efficientnet-b0') # 224\n",
    "model.extract_features(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### modify EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.file_utils import ModelOutput\n",
    "from dataclasses import dataclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EfficientNetOutput(ModelOutput):\n",
    "    loss: torch.FloatTensor = None\n",
    "    logits: torch.FloatTensor = None\n",
    "    features: torch.FloatTensor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetModify(EfficientNet):\n",
    "    def __init__(self, blocks_args=None, global_params=None):\n",
    "        super().__init__(blocks_args, global_params)\n",
    "        \n",
    "    def forward(self, \n",
    "                inputs=None, \n",
    "                labels=None):\n",
    "        print(\"QQQQQQQQQQQQQQQQQQQQQQQQ\")\n",
    "        features = super().forward(inputs)\n",
    "        \n",
    "        if self._global_params.include_top:\n",
    "            logits = features\n",
    "            features = None\n",
    "        else:\n",
    "            x = features.flatten(start_dim=1)\n",
    "            x = self._dropout(x)\n",
    "            logits = self._fc(x)\n",
    "        \n",
    "        loss = None\n",
    "        if labels != None:\n",
    "            loss_fun = CrossEntropyLoss()\n",
    "            loss = loss_fun(logits, labels)\n",
    "        \n",
    "        return EfficientNetOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            features=features\n",
    "        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNetOutput([('loss', tensor(1.5200, grad_fn=<NllLossBackward>)),\n",
       "                    ('logits',\n",
       "                     tensor([[-0.0974,  0.1277,  0.1516,  0.0656, -0.0837]],\n",
       "                            grad_fn=<AddmmBackward>)),\n",
       "                    ('features', tensor([[[[0.1790]],\n",
       "                     \n",
       "                              [[0.2258]],\n",
       "                     \n",
       "                              [[0.0878]],\n",
       "                     \n",
       "                              ...,\n",
       "                     \n",
       "                              [[0.1900]],\n",
       "                     \n",
       "                              [[0.0906]],\n",
       "                     \n",
       "                              [[0.1389]]]], grad_fn=<MeanBackward1>))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new = EfficientNetModify.from_pretrained('efficientnet-b0', num_classes = 5, include_top=False)\n",
    "model_new(img, torch.tensor([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lisa\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetOutput(loss=tensor(1.5492, grad_fn=<NllLossBackward>), logits=tensor([[-0.0697,  0.0590,  0.1366,  0.0343, -0.1071],\n",
      "        [-0.2304,  0.0861,  0.1173,  0.1579, -0.1010]],\n",
      "       grad_fn=<AddmmBackward>), features=tensor([[[[-0.0724]],\n",
      "\n",
      "         [[-0.0979]],\n",
      "\n",
      "         [[ 0.1475]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1349]],\n",
      "\n",
      "         [[ 0.2845]],\n",
      "\n",
      "         [[ 0.5453]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2559]],\n",
      "\n",
      "         [[ 0.5480]],\n",
      "\n",
      "         [[ 0.2489]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2155]],\n",
      "\n",
      "         [[-0.0297]],\n",
      "\n",
      "         [[-0.1406]]]], grad_fn=<MeanBackward1>))\n",
      "EfficientNetOutput(loss=tensor(1.7072, grad_fn=<NllLossBackward>), logits=tensor([[-2.4262e-01,  2.1429e-04,  2.7764e-01,  1.4214e-01, -1.2547e-01],\n",
      "        [ 1.3317e-01,  1.6521e-01,  1.2484e-01, -5.3809e-03,  2.4409e-02]],\n",
      "       grad_fn=<AddmmBackward>), features=tensor([[[[-0.0634]],\n",
      "\n",
      "         [[ 0.3243]],\n",
      "\n",
      "         [[ 0.2773]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2529]],\n",
      "\n",
      "         [[ 0.0617]],\n",
      "\n",
      "         [[ 0.2084]]],\n",
      "\n",
      "\n",
      "        [[[-0.0814]],\n",
      "\n",
      "         [[ 0.0207]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0412]],\n",
      "\n",
      "         [[ 0.2396]],\n",
      "\n",
      "         [[ 0.0495]]]], grad_fn=<MeanBackward1>))\n",
      "EfficientNetOutput(loss=tensor(1.6719, grad_fn=<NllLossBackward>), logits=tensor([[-0.2233,  0.0692, -0.1048,  0.0618, -0.0088],\n",
      "        [ 0.0718,  0.1239,  0.2552,  0.1400, -0.1292]],\n",
      "       grad_fn=<AddmmBackward>), features=tensor([[[[-0.0495]],\n",
      "\n",
      "         [[-0.0316]],\n",
      "\n",
      "         [[-0.1280]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2974]],\n",
      "\n",
      "         [[ 0.1875]],\n",
      "\n",
      "         [[-0.0453]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2558]],\n",
      "\n",
      "         [[ 0.3592]],\n",
      "\n",
      "         [[ 0.5736]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0235]],\n",
      "\n",
      "         [[ 0.1256]],\n",
      "\n",
      "         [[ 0.3350]]]], grad_fn=<MeanBackward1>))\n",
      "EfficientNetOutput(loss=tensor(1.7580, grad_fn=<NllLossBackward>), logits=tensor([[-0.1991, -0.0717,  0.1188,  0.1615, -0.1133],\n",
      "        [ 0.0068,  0.2461,  0.1425, -0.1275,  0.0297]],\n",
      "       grad_fn=<AddmmBackward>), features=tensor([[[[ 0.0868]],\n",
      "\n",
      "         [[-0.0663]],\n",
      "\n",
      "         [[ 0.0539]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0315]],\n",
      "\n",
      "         [[ 0.0653]],\n",
      "\n",
      "         [[ 0.3957]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2260]],\n",
      "\n",
      "         [[ 0.1150]],\n",
      "\n",
      "         [[ 0.1656]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1889]],\n",
      "\n",
      "         [[ 0.2851]],\n",
      "\n",
      "         [[-0.0069]]]], grad_fn=<MeanBackward1>))\n",
      "EfficientNetOutput(loss=tensor(1.6436, grad_fn=<NllLossBackward>), logits=tensor([[-0.0468,  0.1205,  0.0812, -0.0619,  0.0091],\n",
      "        [-0.1095,  0.1094,  0.0938,  0.1583, -0.2175]],\n",
      "       grad_fn=<AddmmBackward>), features=tensor([[[[ 0.3825]],\n",
      "\n",
      "         [[-0.0739]],\n",
      "\n",
      "         [[ 0.3408]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0505]],\n",
      "\n",
      "         [[ 0.4899]],\n",
      "\n",
      "         [[ 0.3849]]],\n",
      "\n",
      "\n",
      "        [[[-0.0072]],\n",
      "\n",
      "         [[ 0.3610]],\n",
      "\n",
      "         [[-0.0760]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1900]],\n",
      "\n",
      "         [[-0.0693]],\n",
      "\n",
      "         [[ 0.0054]]]], grad_fn=<MeanBackward1>))\n"
     ]
    }
   ],
   "source": [
    "for i,j in train_dataloader:\n",
    "    output = model_new(inputs = i, labels = torch.tensor(j)-1)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, EvaluationStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    \"num_train_epochs\":1,          # 訓練代數\n",
    "    \"per_device_train_batch_size\":2,    # train時的batch size\n",
    "    \"per_device_eval_batch_size\":2,    # eval時的batch size\n",
    "    \"gradient_accumulation_steps\":8,    # 每幾個batch update一次參數\n",
    "    \"warmup_steps\":500,          # 前幾個batch要做warm up\n",
    "    \"weight_decay\":0.00001,          # learning rate\n",
    "    \"eval_steps\":500,            # 每幾個step要eval 預設500\n",
    "    \"save_steps\":500,            # 每幾個step要save 預設500\n",
    "    \"logging_steps\":100,\n",
    "    \"evaluation_strategy\":EvaluationStrategy.STEPS,   # 用STEPS來判斷是否要eval\n",
    "    \"dataloader_num_workers\":4,      # 開幾個CPU做dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_setting = {\n",
    "                # -----data setting-----\n",
    "                \"train_dataset\" : train_dataset,\n",
    "#                 \"eval_dataset\" : valid_dataset,\n",
    "#                 \"train_sampler\" : weight_sampler,\n",
    "#                 \"compute_metrics\":metric.entity_mention_metric\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "                                  output_dir=\"./results\",  # 輸出模型的資料夾\n",
    "                                  **args_dict\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainer(Trainer):\n",
    "    def _prepare_inputs(self, inputdata):\n",
    "        print(\"QQQ\")\n",
    "        print(inputdata)\n",
    "        print(inputdata[0].shape)\n",
    "        if isinstance(inputdata, dict):\n",
    "            return super()._prepare_inputs(inputdata)\n",
    "            print(inputdata)\n",
    "        elif isinstance(inputdata, (torch.Tensor,list)) :\n",
    "            print(\"~~~~~~~~~~\")\n",
    "            inputs = {}\n",
    "            inputs[\"inputs\"] = torch.tensor(inputdata[0])\n",
    "            inputs[\"labels\"] = torch.tensor(inputdata[1])\n",
    "            print(inputs)\n",
    "            return super()._prepare_inputs(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get trainer\n",
    "trainer = MyTrainer(\n",
    "                    model=model,\n",
    "                    args=training_args,\n",
    "                    train_dataset = train_dataset,\n",
    "                    data_collator = default_collate\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QQQ\n",
      "[tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          ...,\n",
      "          [ 1.8379,  0.7419, -1.3302,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [ 2.0777,  1.7865,  1.5468,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          ...,\n",
      "          [ 1.8683,  1.2731, -1.0553,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [ 2.2010,  2.0434,  1.7108,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          ...,\n",
      "          [ 1.8208,  1.8383, -0.5321,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [ 2.3263,  2.3437,  1.9603,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          ...,\n",
      "          [-2.1179,  1.9578,  1.9578,  ...,  1.9578,  1.9578,  1.9578],\n",
      "          [-2.1179,  1.9578,  1.9578,  ...,  1.9578,  1.9578,  1.9578],\n",
      "          [-2.1179,  1.9578,  1.9578,  ...,  1.9578,  1.9578,  1.9578]],\n",
      "\n",
      "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          ...,\n",
      "          [-2.0357,  2.1310,  2.1310,  ...,  2.1310,  2.1310,  2.1310],\n",
      "          [-2.0357,  2.1310,  2.1310,  ...,  2.1310,  2.1310,  2.1310],\n",
      "          [-2.0357,  2.1310,  2.1310,  ...,  2.1310,  2.1310,  2.1310]],\n",
      "\n",
      "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          ...,\n",
      "          [-1.8044,  2.3437,  2.3437,  ...,  2.3437,  2.3437,  2.3437],\n",
      "          [-1.8044,  2.3437,  2.3437,  ...,  2.3437,  2.3437,  2.3437],\n",
      "          [-1.8044,  2.3437,  2.3437,  ...,  2.3437,  2.3437,  2.3437]]]]), tensor([4, 2])]\n",
      "torch.Size([2, 3, 224, 224])\n",
      "~~~~~~~~~~\n",
      "{'inputs': tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          ...,\n",
      "          [ 1.8379,  0.7419, -1.3302,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [ 2.0777,  1.7865,  1.5468,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          ...,\n",
      "          [ 1.8683,  1.2731, -1.0553,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [ 2.2010,  2.0434,  1.7108,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          ...,\n",
      "          [ 1.8208,  1.8383, -0.5321,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [ 2.3263,  2.3437,  1.9603,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          ...,\n",
      "          [-2.1179,  1.9578,  1.9578,  ...,  1.9578,  1.9578,  1.9578],\n",
      "          [-2.1179,  1.9578,  1.9578,  ...,  1.9578,  1.9578,  1.9578],\n",
      "          [-2.1179,  1.9578,  1.9578,  ...,  1.9578,  1.9578,  1.9578]],\n",
      "\n",
      "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          ...,\n",
      "          [-2.0357,  2.1310,  2.1310,  ...,  2.1310,  2.1310,  2.1310],\n",
      "          [-2.0357,  2.1310,  2.1310,  ...,  2.1310,  2.1310,  2.1310],\n",
      "          [-2.0357,  2.1310,  2.1310,  ...,  2.1310,  2.1310,  2.1310]],\n",
      "\n",
      "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          ...,\n",
      "          [-1.8044,  2.3437,  2.3437,  ...,  2.3437,  2.3437,  2.3437],\n",
      "          [-1.8044,  2.3437,  2.3437,  ...,  2.3437,  2.3437,  2.3437],\n",
      "          [-1.8044,  2.3437,  2.3437,  ...,  2.3437,  2.3437,  2.3437]]]]), 'labels': tensor([4, 2])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lisa\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\Lisa\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\lisa\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, model_path, trial)\u001b[0m\n\u001b[0;32m    773\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m                     \u001b[0mtr_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    776\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_total_flos\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lisa\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   1110\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lisa\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[0mSubclass\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0moverride\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcustom\u001b[0m \u001b[0mbehavior\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \"\"\"\n\u001b[1;32m-> 1136\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1137\u001b[0m         \u001b[1;31m# Save past state if it exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpast_index\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lisa\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'labels'"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
