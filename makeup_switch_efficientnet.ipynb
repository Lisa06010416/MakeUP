{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "makeup_switch_efficientnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLLyLTszUVTN"
      },
      "source": [
        "## Mount to Google Driver"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdIkNLZnI4WO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1dd64fd-6ec2-4371-85bf-4fa7cb569e3b"
      },
      "source": [
        "mount_path = \"MakeUP\"\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    import os\n",
        "    drive.mount('/content/gdrive/', force_remount=True)\n",
        "    os.chdir(os.path.join('/content/gdrive/My Drive/',mount_path))\n",
        "    print(\"save result at google driver\")\n",
        "except:\n",
        "    print(\"save result at local\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n",
            "save result at google driver\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install ."
      ],
      "metadata": {
        "id": "zF5U7drsnFPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaQvtUCRLVLy"
      },
      "source": [
        "## Check/install envs and import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7epblTaJiSy"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "from makeup.model.efficientnet import EfficientNetModify, imageclassify_collect_fn\n",
        "from makeup.model.metrics import acc_metrics\n",
        "from makeup.utils import logmanager\n",
        "logger = logmanager.get_logger(__name__)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYybBl-bLlbO"
      },
      "source": [
        "## Par Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2D7bMjg1MoY"
      },
      "source": [
        "image_size = 224\n",
        "train_data_path = \"dataset/train/\"\n",
        "valid_data_path = \"dataset/valid/\"\n",
        "\n",
        "model_name = 'efficientnet-b4'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo2sUtMi1Moa"
      },
      "source": [
        "#### image process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99qoux_t1Moc"
      },
      "source": [
        "# 準備訓練資料\n",
        "# ImageFolder假設指定路徑下有多個資料夾，每個資料夾內為同一類的圖片，資料加名稱類別名\n",
        "train_dataset = datasets.ImageFolder(train_data_path,\n",
        "                                     transforms.Compose([\n",
        "                                        transforms.Resize(image_size),\n",
        "                                        transforms.CenterCrop(image_size),\n",
        "                                        transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
        "                                        transforms.RandomHorizontalFlip(),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                                     ]))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb2d7yB_-SWg"
      },
      "source": [
        "# 準備訓練資料\n",
        "# ImageFolder假設指定路徑下有多個資料夾，每個資料夾內為同一類的圖片，資料加名稱類別名\n",
        "valid_dataset = datasets.ImageFolder(valid_data_path,\n",
        "                                     transforms.Compose([\n",
        "                                        transforms.Resize(image_size),\n",
        "                                        transforms.CenterCrop(image_size),\n",
        "                                        transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
        "                                        transforms.RandomHorizontalFlip(),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                                     ]))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp8uVmu71Mod"
      },
      "source": [
        "#### modify EfficientNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOQAYX7p1Moe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd262d82-5910-4b18-f094-3a7c48ae3597"
      },
      "source": [
        "model_1 = EfficientNetModify.from_pretrained(model_name, num_classes = 4, include_top=False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBe5JXjl1Mof"
      },
      "source": [
        "#### Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxhsTeH31Moh"
      },
      "source": [
        "training_args = TrainingArguments(\n",
        "                                    output_dir=\"./results\",  # 輸出模型的資料夾\n",
        "                                    num_train_epochs=50,          # 訓練代數\n",
        "                                    per_device_train_batch_size=32,    # train時的batch size\n",
        "                                    per_device_eval_batch_size=32,    # eval時的batch size\n",
        "                                    gradient_accumulation_steps=1,    # 每幾個batch update一次參數\n",
        "                                    load_best_model_at_end=True, # 訓練完後自動讀取最佳的model, trainer 會忽略 save_strategy,save_steps 在每次eval後存模型\n",
        "                                    warmup_steps=500,          # 前幾個batch要做warm up\n",
        "                                    weight_decay=0.00001,          # learning rate decay\n",
        "                                    eval_steps=50,            # 每幾個step要eval 預設500\n",
        "                                    # save_steps=50,            # 每幾個step要save 預設500\n",
        "                                    logging_steps=1,         \n",
        "                                    evaluation_strategy=\"steps\",   # 用STEPS來判斷是否要eval\n",
        "                                    dataloader_num_workers=2,      # 開幾個CPU做dataloader\n",
        "                                 )"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zRfyFsu1Moh"
      },
      "source": [
        "# get trainer\n",
        "trainer = Trainer(\n",
        "                    model=model_1,\n",
        "                    args=training_args,\n",
        "                    train_dataset = train_dataset,\n",
        "                    eval_dataset = valid_dataset,\n",
        "                    data_collator = imageclassify_collect_fn,\n",
        "                    compute_metrics = acc_metrics\n",
        "                  )"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM11h9_d1Moi"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gehM4-kMoRCZ"
      },
      "source": [
        "## Show Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x05qJhiLoQck"
      },
      "source": [
        "modelpath = \"./results/checkpoint-500/pytorch_model.bin\"\n",
        "\n",
        "model = EfficientNetModify.from_pretrained(model_name, weights_path=modelpath, num_classes = 4, include_top=False, load_fc=True)\n",
        "\n",
        "# get trainer\n",
        "trainer = Trainer(\n",
        "                    model=model,\n",
        "                    args=training_args,\n",
        "                    train_dataset = train_dataset,\n",
        "                    eval_dataset = valid_dataset,\n",
        "                    data_collator = imageclassify_collect_fn,\n",
        "                    compute_metrics = acc_metrics\n",
        "                  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YljbsMlcIaDR"
      },
      "source": [
        "predict = trainer.predict(valid_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D7Z392z4d0V"
      },
      "source": [
        "valid_dataset.classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVb602BzX249"
      },
      "source": [
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "plt.show()\n",
        "\n",
        "def desplay_image(path):\n",
        "    im = Image.open(path)\n",
        "    im = im.resize((100, 100))\n",
        "    if envchecker.is_in_notebook():\n",
        "        display(im)\n",
        "    else:\n",
        "        im.show() \n",
        "\n",
        "def show_confusion_matrix(true, predict, x=True, y=True):\n",
        "    cm = confusion_matrix(true, predict)\n",
        "    sns.heatmap(cm, xticklabels=x, yticklabels=y)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def show_result_classfyimg(predict, dataset):\n",
        "    metric = predict.metrics\n",
        "    predict_labels = predict.predictions[0].argmax(-1)\n",
        "    labels = predict.label_ids\n",
        "    index = 0\n",
        "    print(\"------------ Metrics ------------\")\n",
        "    for k in predict.metrics:\n",
        "        print(\"{} : {}\".format(k, predict.metrics[k]))\n",
        "\n",
        "    print(\"------------ Confuse metric ------------\")\n",
        "    show_confusion_matrix(labels, predict_labels, dataset.classes, dataset.classes)\n",
        "\n",
        "    print(\"------------ Show error img ------------\")\n",
        "    for predict_label, label, sample in zip(predict_labels,labels,dataset.samples):\n",
        "        if predict_label != label:\n",
        "            print(\"label {}\".format(dataset.classes[label]))\n",
        "            print(\"predict {}\".format(dataset.classes[predict_label]))\n",
        "            desplay_image(sample[0]) \n",
        "            print()\n",
        "        index+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka0vYPW1DmM2"
      },
      "source": [
        "show_result_classfyimg(predict, valid_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}